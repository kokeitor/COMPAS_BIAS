# üìä Evaluaci√≥n del Sesgo en el Algoritmo COMPAS

## Introducci√≥n

En este notebook, se llevar√° a cabo un an√°lisis exhaustivo del sesgo presente en el algoritmo COMPAS (Correctional Offender Management Profiling for Alternative Sanctions). COMPAS es una herramienta ampliamente utilizada en el sistema de justicia penal de los Estados Unidos para evaluar la probabilidad de reincidencia de los acusados. Esta herramienta proporciona puntuaciones de riesgo que son utilizadas por jueces y oficiales de libertad condicional para tomar decisiones informadas sobre la detenci√≥n, sentencia y liberaci√≥n de los acusados.

### Contexto del Algoritmo COMPAS

COMPAS utiliza una serie de factores, incluyendo datos demogr√°ficos y antecedentes penales, para generar una puntuaci√≥n de riesgo (campo *decile_score* en el dataset) que var√≠a entre 1 y 10. Esta puntuaci√≥n indica la probabilidad de que un individuo cometa un nuevo delito en el futuro. Sin embargo, estudios recientes han planteado preocupaciones significativas sobre la equidad de COMPAS, se√±alando que el algoritmo puede estar sesgado en contra de ciertos grupos demogr√°ficos, especialmente los afroamericanos.

### Objetivo del An√°lisis

El objetivo principal de este an√°lisis es evaluar el sesgo racial en el algoritmo COMPAS, espec√≠ficamente c√≥mo afecta a los individuos afroamericanos en comparaci√≥n con otros grupos demogr√°ficos. Tambi√©n se investigar√° otro posible sesgo existente en la caracter√≠stica de g√©nero o "sex" en el dataset. Para lograr esto, se llevar√°n a cabo las siguientes tareas:

1. **üîç Exploraci√≥n y Transformaci√≥n de Datos**: Se analizar√° el conjunto de datos de manera visual y estad√≠stica para comprender su estructura y caracter√≠sticas. Incluye la eliminaci√≥n de ciertas variables no √∫tiles, codificaci√≥n de variables y establecimiento de un umbral para las probabilidades otorgadas por COMPAS. De esta forma se logra una nueva columna *compas_recid* binaria para comparar con el ground truth de reincidencia (*is_recid*).
2. **ü§ñ Modelo *Custom***: Se crear√° y entrenar√° una pipeline con la que despu√©s se predice. Esta pipeline incluye un modelo ensamblado binario. Las predicciones de este modelo se usan para comparar y evaluar el sesgo de COMPAS.
3. **üìà C√°lculo de M√©tricas de Rendimiento**: Se evaluar√° la precisi√≥n, recall, F1-score y otras m√©tricas del modelo COMPAS y del modelo custom y se comparar√°n.
4. **üîç An√°lisis de la Matriz de Confusi√≥n**: Se comparar√°n las tasas de falsos positivos (FP) y falsos negativos (FN) entre diferentes grupos raciales y entre ambos modelos.
5. **üìâ Curvas ROC**: Se generar√°n y analizar√°n las curvas ROC para distintos grupos demogr√°ficos.
6. **‚öñÔ∏è Identificaci√≥n de Disparidades**: Se identificar√°n y cuantificar√°n las disparidades en las tasas de error de predicci√≥n entre los grupos demogr√°ficos y entre los g√©neros.
7. **üìù Recomendaciones**: Se proporcionar√°n recomendaciones sobre c√≥mo abordar los sesgos identificados en el modelo COMPAS y posibles siguientes pasos.

### Estructura del Notebook

1. **üì• Carga de Datos y Preprocesamiento**: Se importar√° el conjunto de datos de COMPAS y se realizar√°n las transformaciones necesarias para su an√°lisis.
2. **üìä Exploraci√≥n de Datos**: Se visualizar√°n y describir√°n las caracter√≠sticas principales del conjunto de datos.
3. **üèãÔ∏è‚Äç‚ôÇÔ∏è Entrenamiento de Modelos**: Se entrenar√° un modelo "custom" y se comparar√° su rendimiento con el modelo COMPAS.
4. **üîç Evaluaci√≥n de Sesgo**: Se realizar√°n an√°lisis detallados de las m√©tricas de rendimiento y se evaluar√° el sesgo racial.
5. **üìú Conclusiones y Recomendaciones**: Se discutir√°n los resultados obtenidos y se proporcionar√°n recomendaciones para abordar los sesgos identificados.

### Fuentes de Informaci√≥n

- **COMPAS Dataset**: [ProPublica COMPAS Data](https://github.com/propublica/compas-analysis)
- **Estudios sobre Sesgo en COMPAS**: 
  - [Machine Bias - ProPublica](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing)
  - [Fairness and Machine Learning - O'Reilly Media](https://www.oreilly.com/library/view/fairness-and-machine/9781492071256/)
- **Herramientas Utilizadas**:
  - [AIF360 - A comprehensive toolkit for fairness in AI](https://aif360.mybluemix.net/)
  - [Scikit-Learn - Machine Learning in Python](https://scikit-learn.org/stable/)

A lo largo de este notebook, no solo se buscar√° identificar los sesgos presentes, sino tambi√©n proporcionar un marco para mitigarlos, asegurando as√≠ que las herramientas de evaluaci√≥n de riesgos sean m√°s justas y equitativas.

